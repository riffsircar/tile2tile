{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, random, torch, os, math, json, sys, re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from model_lin import get_model, load_model\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "device = torch.device('cuda')\n",
    "latent_dim = 32 # size of latent vector\n",
    "batch_size = 32 # input batch size\n",
    "GAME = 'mm'\n",
    "\n",
    "smb_folder = 'smb_chunks_all/'\n",
    "ki_folder = 'ki_chunks_all/'\n",
    "mm_folder = 'mm_chunks_all/'\n",
    "ng_folder = 'ng_chunks/'\n",
    "met_folder = 'met_chunks_all/'\n",
    "\n",
    "folders = {'smb':smb_folder,'ki':ki_folder,'mm':mm_folder,'ng':ng_folder,'met':met_folder}\n",
    "\n",
    "folder = folders[GAME]\n",
    "#manual_seed = random.randint(1, 10000)\n",
    "#random.seed(manual_seed)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)\n",
    "    \n",
    "def parse_folder(folder):\n",
    "    levels, dirs = [], []\n",
    "    text = ''\n",
    "    files = os.listdir(folder)\n",
    "    files[:] = (value for value in files if value != '.')\n",
    "    files = natural_sort(files)\n",
    "    for file in files:\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        with open(os.path.join(folder,file),'r') as infile:\n",
    "            #print(infile)\n",
    "            level = []\n",
    "            for line in infile:\n",
    "                text += line\n",
    "                level.append(list(line.rstrip()))\n",
    "            #level = [list(line.rstrip()) for line in infile]\n",
    "            #level = [line.rstrip() for line in infile]\n",
    "            #print(level)\n",
    "            levels.append(level)\n",
    "            #print(levels)\n",
    "    return levels, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "Num batches:  4.46875\n",
      "{'#': 0, '*': 1, '+': 2, '-': 3, 'B': 4, 'C': 5, 'H': 6, 'L': 7, 'M': 8, 'P': 9, 'U': 10, 'W': 11, 'l': 12, 't': 13, 'w': 14, '|': 15}\n",
      "{'X': 0, 'E': 1, '|': 2, '*': 3, '-': 4}\n",
      "{0: 'X', 1: 'E', 2: '|', 3: '*', 4: '-'}\n",
      "Tiles:  16\n",
      "Sketch Tiles:  5\n",
      "(143, 15, 16) (143, 15, 16)\n",
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (fc1): Linear(in_features=1200, out_features=1024, bias=True)\n",
      "    (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc41): Linear(in_features=256, out_features=32, bias=True)\n",
      "    (fc42): Linear(in_features=256, out_features=32, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc5): Linear(in_features=32, out_features=256, bias=True)\n",
      "    (fc6): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (fc7): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (fc8): Linear(in_features=1024, out_features=3840, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def pipe_check(level):\n",
    "    temp = ''\n",
    "    for l in level:\n",
    "        temp += ''.join(l)\n",
    "    if '[' in temp and ']' not in temp:\n",
    "        return False\n",
    "    if ']' in temp and '[' not in temp:\n",
    "        return False\n",
    "    if '<' in temp and '>' not in temp:\n",
    "        return False\n",
    "    if '>' in temp and '<' not in temp:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "next_dirs = []\n",
    "levels, text = parse_folder(folder)\n",
    "\n",
    "text = text.replace('\\n','')\n",
    "print(len(levels))\n",
    "print(\"Num batches: \", len(levels)/batch_size)\n",
    "chars = sorted(list(set(text.strip('\\n'))))\n",
    "#sketch_chars = ['X','E','|','*','P','-']\n",
    "sketch_chars = ['X','E','|','*','-']\n",
    "#print(lr_chars)\n",
    "int2char = dict(enumerate(chars))\n",
    "int2sc = dict(enumerate(sketch_chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "sc2int = {ch: ii for ii, ch in int2sc.items()}\n",
    "print(char2int)\n",
    "print(sc2int)\n",
    "print(int2sc)\n",
    "num_tiles = len(char2int)\n",
    "num_sketch_tiles = len(sc2int)\n",
    "print('Tiles: ', num_tiles)\n",
    "print('Sketch Tiles: ', num_sketch_tiles)\n",
    "\n",
    "\n",
    "def translate_mm(level):\n",
    "    outs = []\n",
    "    label_size = len(sc2int)-1\n",
    "    for p in range(1,int(math.pow(2,label_size))):\n",
    "        label = [int(i) for i in bin(p)[2:]]\n",
    "        label = [0] * (label_size - len(label)) + label\n",
    "        ones = [i for i, j in enumerate(label) if j == 1]\n",
    "        t_level = []\n",
    "        for line in level:\n",
    "            t_line = ''\n",
    "            for c in line:\n",
    "                if c in '#BM':\n",
    "                    t_line += 'X'\n",
    "                elif c in 'CHt':\n",
    "                    t_line += 'E'\n",
    "                elif c in 'D|':\n",
    "                    t_line += '|'\n",
    "                elif c in '*+LUWlw':\n",
    "                    t_line += '*'\n",
    "                else:\n",
    "                    t_line += c\n",
    "            t_line = [l if sc2int[l] in ones else '-' for l in t_line]\n",
    "            t_level.append(t_line)\n",
    "        if t_level not in outs:\n",
    "            outs.append(t_level)\n",
    "    return outs\n",
    "\n",
    "def translate_ki(level):\n",
    "    outs = []\n",
    "    label_size = len(sc2int)-1\n",
    "    for p in range(1,int(math.pow(2,label_size))):\n",
    "        label = [int(i) for i in bin(p)[2:]]\n",
    "        label = [0] * (label_size - len(label)) + label\n",
    "        ones = [i for i, j in enumerate(label) if j == 1]\n",
    "        t_level = []\n",
    "        for line in level:\n",
    "            t_line = ''\n",
    "            for c in line:\n",
    "                if c in '#MT':\n",
    "                    t_line += 'X'\n",
    "                elif c in 'H':\n",
    "                    t_line += 'E'\n",
    "                elif c in 'D':\n",
    "                    t_line += '|'\n",
    "                else:\n",
    "                    t_line += c\n",
    "            t_line = [l if sc2int[l] in ones else '-' for l in t_line]\n",
    "            t_level.append(t_line)\n",
    "        if t_level not in outs:\n",
    "            outs.append(t_level)\n",
    "    return outs\n",
    "\n",
    "def translate_ki_lean(level):\n",
    "    t_level = []\n",
    "    for line in level:\n",
    "        t_line = ''\n",
    "        for c in line:\n",
    "            if c in '#MT':\n",
    "                t_line += 'X'\n",
    "            elif c in 'H':\n",
    "                t_line += 'E'\n",
    "            elif c in 'D':\n",
    "                t_line += '|'\n",
    "            elif c in 'P':\n",
    "                t_line += '-'\n",
    "            else:\n",
    "                t_line += c\n",
    "        t_level.append(t_line)\n",
    "    return [t_level]\n",
    "\n",
    "\n",
    "def translate_smb(level):\n",
    "    outs = []\n",
    "    label_size = len(sc2int)-1\n",
    "    for p in range(1,int(math.pow(2,label_size))):\n",
    "        label = [int(i) for i in bin(p)[2:]]\n",
    "        label = [0] * (label_size - len(label)) + label\n",
    "        ones = [i for i, j in enumerate(label) if j == 1]\n",
    "        t_level = []\n",
    "        for line in level:\n",
    "            t_line = ''\n",
    "            for c in line:\n",
    "                if c in 'X<>[]S':\n",
    "                    t_line += 'X'\n",
    "                elif c in 'o?Q':\n",
    "                    t_line += '*'\n",
    "                else:\n",
    "                    t_line += c\n",
    "            t_line = [l if sc2int[l] in ones else '-' for l in t_line]\n",
    "            t_level.append(t_line)\n",
    "        if t_level not in outs:\n",
    "            outs.append(t_level)\n",
    "    return outs\n",
    "\n",
    "def translate_smb_lean(level):\n",
    "    t_level = []\n",
    "    for line in level:\n",
    "        t_line = ''\n",
    "        for c in line:\n",
    "            if c in 'X<>[]S':\n",
    "                t_line += 'X'\n",
    "            elif c in 'o?Q':\n",
    "                t_line += '*'\n",
    "            elif c in 'Bb':\n",
    "                t_line += 'E'\n",
    "            else:\n",
    "                t_line += c\n",
    "        t_level.append(t_line)\n",
    "    return [t_level]\n",
    "\n",
    "def translate_mm_lean(level):\n",
    "    t_level = []\n",
    "    for line in level:\n",
    "        t_line = ''\n",
    "        for c in line:\n",
    "            if c in '#BM':\n",
    "                t_line += 'X'\n",
    "            elif c in 'CHt':\n",
    "                t_line += 'E'\n",
    "            elif c in 'D|':\n",
    "                t_line += '|'\n",
    "            elif c in '*+LUWlw':\n",
    "                t_line += '*'\n",
    "            elif c in 'P':\n",
    "                t_line += '-'\n",
    "            else:\n",
    "                t_line += c\n",
    "        t_level.append(t_line)\n",
    "    return [t_level]\n",
    "\n",
    "            \n",
    "translate = {'smb':translate_smb_lean, 'ki':translate_ki_lean, 'mm':translate_mm_lean}\n",
    "inputs, targets = [], []\n",
    "for level in levels:\n",
    "    if GAME == 'smb' and not pipe_check(level):\n",
    "        continue\n",
    "    tar, inp = [], []\n",
    "    translate_func = translate[GAME]\n",
    "    t_levels = translate_func(level)\n",
    "    for t_level in t_levels:\n",
    "        inp = []\n",
    "        for line in t_level:\n",
    "            encoded_line = [sc2int[x] for x in line]\n",
    "            inp.append(encoded_line)\n",
    "        inputs.append(inp)\n",
    "    for line in level:\n",
    "        encoded_line = [char2int[x] for x in line]\n",
    "        tar.append(encoded_line)\n",
    "    for _ in range(len(t_levels)):\n",
    "        targets.append(tar)\n",
    "    \n",
    "inputs = np.array(inputs)\n",
    "targets = np.array(targets)\n",
    "print(inputs.shape, targets.shape)\n",
    "\n",
    "inputs_onehot = np.eye(num_sketch_tiles, dtype='uint8')[inputs]\n",
    "inputs_onehot = np.rollaxis(inputs_onehot, 3, 1)\n",
    "targets_onehot = np.eye(num_tiles, dtype='uint8')[targets]\n",
    "targets_onehot = np.rollaxis(targets_onehot, 3, 1)\n",
    "\n",
    "inputs_train = torch.from_numpy(inputs_onehot).to(dtype=torch.float64)\n",
    "targets_train = torch.from_numpy(targets_onehot).to(dtype=torch.float64)\n",
    "train_ds = TensorDataset(inputs_train,targets_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "vae, opt = get_model(device, 240, num_sketch_tiles, num_tiles, latent_dim,1e-3)\n",
    "#vae, opt = get_conv_big_model(device, num_sketch_tiles, num_tiles, latent_dim)\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, step_size=2500)\n",
    "print(vae)\n",
    "#sys.exit()\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    #BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')/recon_x.size(0)\n",
    "    #BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1200])\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'filter_vae_fc_nored_' + GAME + '_ld_' + str(latent_dim)\n",
    "out_file = open(model_name + '_loss.csv','w')\n",
    "out_file.write('Train Loss,KLD,KLW\\n')\n",
    "epochs = 10000 # num epochs to train for\n",
    "k = 0.0025\n",
    "rate = 2500\n",
    "\n",
    "for i in range(epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    kld_loss = 0\n",
    "    for batch, (x,y) in enumerate(train_dl):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_lin = x.view(x.size(0),-1)\n",
    "        print(x_lin.shape)\n",
    "        sys.exit()\n",
    "        opt.zero_grad()\n",
    "        recon_x_lin, mu, logvar, z = vae(x_lin)\n",
    "        recon_x = recon_x_lin.reshape(recon_x_lin.size(0),y.size(1),x.size(2),x.size(3))\n",
    "        #print(x.shape, recon_x.shape, y.shape)\n",
    "        #sys.exit()\n",
    "        #recon_x, mu, logvar, z = vae(x)\n",
    "        loss, bce, kld = loss_fn(recon_x, y, mu, logvar)\n",
    "        klw = min(1.0, i/rate)\n",
    "        loss = bce + kld*klw\n",
    "        train_loss += loss.item()\n",
    "        kld_loss += kld.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    train_loss /= len(train_dl.dataset)\n",
    "    kld_loss /= len(train_dl.dataset)\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch: ', i,'\\tLoss: ',train_loss,\"\\tKLD: \", kld_loss, \"\\tKLW: \", klw)\n",
    "    if i % 1000 == 0:\n",
    "        torch.save(vae.state_dict(), model_name + '_' + str(i) + '.pth')\n",
    "        out_file.write(str(train_loss)+','+str(kld_loss)+','+str(klw)+'\\n')\n",
    "    scheduler.step()\n",
    "print('Epoch: ', i,'\\tLoss: ',train_loss,\"\\tKLD: \", kld_loss, \"\\tKLW: \", klw)\n",
    "torch.save(vae.state_dict(), model_name + '_final' + '.pth')\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
